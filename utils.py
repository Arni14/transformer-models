import torch


def multi_head_attention():
    raise NotImplementedError


def single_head_attention():
    raise NotImplementedError

def positional_encoding():
    raise NotImplementedError
